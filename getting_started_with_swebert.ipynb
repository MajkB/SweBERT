{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook serves to\n",
    "1. Check SweBERT Model Accessibility\n",
    "\n",
    "and to demonstrate a\n",
    "2. Simple Model Application (Masked Token Prediction)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: Make sure to run this notebook in a virtual environment with the libraries listed in requirements.txt installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To use data.metrics please install scikit-learn. See https://scikit-learn.org/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel, TFBertModel, BertForMaskedLM \n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Choose SweBERT model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have to choose one of the pretrained SweBERT models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'af-ai-center/bert-base-swedish-uncased'\n",
    "# pretrained_model_name = af-ai-center/bert-large-swedish-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check SweBERT Model Accessibility"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, we are going to check that the chosen pretrained SweBERT model is accessible through the transformers library.\n",
    "If it is, we should be able to instantiate a tokenizer and a (PyTorch/TensorFlow) model from it. \n",
    "\n",
    "Note that this may take a while the first time you run it as the model needs to be downloaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Model PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Model TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFBertModel.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple Model Application (Masked Token Prediction)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are now going to apply the (PyTorch) SweBERT model on an example sentence,\n",
    "loosely following https://huggingface.co/transformers/quickstart.html#quick-tour-usage\n",
    "\n",
    "We will\n",
    "1. Preprocess the example\n",
    "2. Tokenize the preprocessed example\n",
    "3. Mask one of the tokens\n",
    "4. Prepare the tokens for use with SweBERT\n",
    "5. Use SweBERT to predict back the masked token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jag är ett barn, och det här är mitt hem. Alltså är det ett barnhem!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Jag är ett barn, och det här är mitt hem. Alltså är det ett barnhem!'\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocess the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. lowercase "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The pretrained SweBERT models are uncased. \n",
    "\n",
    "In principle, there are 2 options to account for this:\n",
    "i)  manually lowercase all text before tokenization (using the string method .lower())\n",
    "ii) let the BertTokenizer take care of lowercasing  (using the parameter do_lower_case=True)\n",
    "\n",
    "We opt for i) because the BertTokenizer does not handle the Swedish letter 'å' properly (it gets replaced by 'a' when do_lower_case=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jag är ett barn, och det här är mitt hem. alltså är det ett barnhem!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_uncased = example.lower()\n",
    "example_uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. special tokens "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The input of BERT models needs to be provided with special tokens '[CLS]' and '[SEP]':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] jag är ett barn, och det här är mitt hem. [SEP] alltså är det ett barnhem! [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_preprocessed = '[CLS] ' + example_uncased.replace('.', '. [SEP]') + ' [SEP]'\n",
    "example_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tokenize the preprocessed example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name, do_lower_case=False)  # see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 tokens:\n",
      "['[CLS]', 'jag', 'är', 'ett', 'barn', ',', 'och', 'det', 'här', 'är', 'mitt', 'hem', '.', '[SEP]', 'alltså', 'är', 'det', 'ett', 'barn', '##hem', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(example_preprocessed)\n",
    "\n",
    "print(f'{len(tokens)} tokens:')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mask one of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'jag', 'är', 'ett', 'barn', ',', 'och', 'det', 'här', 'är', 'mitt', 'hem', '.', '[SEP]', 'alltså', 'är', 'det', 'ett', '[MASK]', '##hem', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "masked_index = 18  # 'barn'\n",
    "tokens[masked_index] = '[MASK]'\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare the tokens for use with SweBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 1112, 1100, 1115, 1255, 1010, 1095, 1102, 1174, 1100, 1352, 1345,\n",
      "         1012,  102, 1492, 1100, 1102, 1115,  103, 2760,  999,  102]])\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens_tensor = torch.tensor([indexed_tokens])\n",
    "print(indexed_tokens_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Use SweBERT to predict back the masked token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = BertForMaskedLM.from_pretrained(pretrained_model_name)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 22, 30522])\n"
     ]
    }
   ],
   "source": [
    "# predict all tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model(indexed_tokens_tensor)\n",
    "\n",
    "predictions = outputs[0]\n",
    "print(predictions.shape)  # 1 example, 21 tokens, 30522 vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1255)\n"
     ]
    }
   ],
   "source": [
    "# show predicted index for masked token\n",
    "predicted_index = torch.argmax(predictions[0, masked_index])\n",
    "print(predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barn\n"
     ]
    }
   ],
   "source": [
    "# show predicted masked token\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predicted_token == 'barn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Instead of looking only at the top model prediction, we can also consider the top 5 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1255, 14829,  8032,  1251,  1264])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top5 predicted index for masked token\n",
    "predicted_index_top5 = torch.argsort(predictions[0, masked_index], descending=True)[:5]\n",
    "predicted_index_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barn\n",
      "barndoms\n",
      "foster\n",
      "dock\n",
      "dag\n"
     ]
    }
   ],
   "source": [
    "# show top5 predicted masked token\n",
    "for predicted_index in predicted_index_top5:\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "    print(predicted_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- We have checked the accessibility of the SweBERT models through the transformers library. \n",
    "- We have demonstrated a very simple model application, where the SweBERT model successfully predicts a masked token.\n",
    "\n",
    "For additional use cases and information, we refer to the documentation of the transformers library. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nlp-swebert",
   "language": "python",
   "name": "venv-nlp-swebert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
