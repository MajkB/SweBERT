{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook serves to\n",
    "1. Check SweBERT Model Accessibility\n",
    "\n",
    "and to demonstrate a\n",
    "2. Simple Model Application (Masked Token Prediction)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: Make sure to run this notebook in a virtual environment with the libraries listed in requirements.txt installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, TFBertModel\n",
    "\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have to choose one of the pretrained SweBERT models (base/large):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = 'af-ai-center/bert-base-swedish-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: REMOVE THIS!!!\n",
    "pretrained_model_name = './private/bert-base-swedish-uncased'\n",
    "pretrained_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check SweBERT Model Accessibility"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First, we are going to check that the chosen pretrained SweBERT model is accessible through the transformers library.\n",
    "If it is, we should be able to instantiate a tokenizer and a (PyTorch/TensorFlow) model from it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Model PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Model TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = TFBertModel.from_pretrained(pretrained_model_name, from_pt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Simple Model Application (Masked Token Prediction)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We are now going to apply the SweBERT model on an example sentence.\n",
    "\n",
    "We will\n",
    "1. Tokenize the example sentence\n",
    "2. Mask one of the tokens\n",
    "3. Prepare the tokens for use with SweBERT\n",
    "4. Use the SweBERT model to predict back the masked token "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Side remark: \n",
    "The pretrained SweBERT models are uncased. \n",
    "\n",
    "In principle, there are 2 options to account for this:\n",
    "i)  uncase all text *before* tokenization (using the string method .lower())\n",
    "ii) uncase all text *during* tokenization (using the BertTokenizer parameter do_lower_case=True)\n",
    "\n",
    "We opt for i) because the BertTokenizer does not handle the Swedish letter 'å' properly (it gets replaced by 'a') when do_lower_case=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sentence = 'Jag är ett barn, och det här är mitt hem. Alltså är det ett barnhem!'.lower()\n",
    "example_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenize the example_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(example_sentence)\n",
    "\n",
    "print(f'{len(tokenized_text)} tokens')\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mask one of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_index = 16  # 'barn'\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare the tokens for use with SweBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens_tensor = torch.tensor([indexed_tokens])\n",
    "print(indexed_tokens_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the SweBERT model to predict back the masked token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = BertForMaskedLM.from_pretrained(pretrained_model_name)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model(indexed_tokens_tensor)\n",
    "\n",
    "predictions = outputs[0]\n",
    "print(predictions.shape)  # 1 example, 19 tokens, 30522 possible token predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predicted index for masked token\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "print(predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predicted masked token\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predicted_token == 'barn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- We have checked the accessibility of the SweBERT models through the transformers library. \n",
    "- We have demonstrated a very simple model application, where the SweBERT model successfully predicts a masked token.\n",
    "\n",
    "For additional use cases and information, we refer to the documentation of the transformers library. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nlp-swebert",
   "language": "python",
   "name": "venv-nlp-swebert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
